{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 4 - Fundamental ML Algorithms Part II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn import tree\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = './dataset/'\n",
    "writePath ='./generated/'\n",
    "\n",
    "df_iris = pd.read_csv(dataPath + 'iris.csv')\n",
    "\n",
    "regex = re.compile('[^\\w\\s]')\n",
    "FEATURES = 10000\n",
    "\n",
    "\n",
    "data_types = ['train', 'valid', 'test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Pre-processing function: lowercase, remove punctuation. Returns list of lists (of clean lines), ratings ''' \n",
    "def pre_process(filePath):\n",
    "    with open(filePath, 'r', encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "        reviews, ratings = [], []\n",
    "        for l in lines:\n",
    "            splitted = l.split('\\t')\n",
    "            ratings.append(int(splitted[1].strip()))\n",
    "            reviews.append(regex.sub('', splitted[0].strip()).lower())\n",
    "\n",
    "    return reviews, ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Function returns takes in list of lists (of lines), returns list of n most freq. words '''\n",
    "def top_n_words(l2d, n):\n",
    "    count = Counter([word for line in l2d for word in line.split()]).most_common(n)\n",
    "    top_features = [word[0] for word in count]\n",
    "\n",
    "    return top_features, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process train, val, test sets of yelp data\n",
    "yelp_tr_x, yelp_tr_rate = pre_process(dataPath + 'yelp-train.txt')\n",
    "yelp_val_x, yelp_val_rate = pre_process(dataPath + 'yelp-valid.txt')\n",
    "yelp_test_x, yelp_test_rate = pre_process(dataPath + 'yelp-test.txt')\n",
    "\n",
    "# Convert to dictionaries\n",
    "yelp_text = {'train': yelp_tr_x, 'valid': yelp_val_x, 'test': yelp_test_x}\n",
    "yelp_ratings = {'train': yelp_tr_rate, 'valid': yelp_val_rate, 'test': yelp_test_rate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return top 10 000 features for dataset\n",
    "yelp_vocab, yelp_count = top_n_words(yelp_tr_x, FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to write vocab.txt files given top 10 000 words in data-sets\n",
    "def vocab_to_txt(vocab_count, filePath, fileName):\n",
    "    write_path = filePath + fileName\n",
    "    yelp_dict = {}\n",
    "    vocab_index = {}\n",
    "    f = open(write_path, 'w')\n",
    "    for i in range(len(vocab_count)):\n",
    "        yelp_dict[vocab_count[i][0]] = vocab_count[i][1]\n",
    "        vocab_index[vocab_count[i][0]] = i\n",
    "        f.write(vocab_count[i][0] + ' ' + str(i)+ ' ' + str(vocab_count[i][1]) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "    return yelp_dict, vocab_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict, vocab_indices = vocab_to_txt(yelp_count, writePath,'yelp-vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that converts pre-processed text to binary, frequency bag-of-words representations\n",
    "def convert_bow(text, ratings):\n",
    "    bin = {}\n",
    "    freq = {}\n",
    "\n",
    "    vectorizer = CountVectorizer(vocabulary=yelp_vocab)\n",
    "    vectorizer_bin = CountVectorizer(vocabulary=yelp_vocab, binary=True)\n",
    "\n",
    "    for type in data_types:\n",
    "        v_freq = np.array(normalize(vectorizer.fit_transform(text[type]).todense()))\n",
    "        v_bin = sparse.csr_matrix(np.array(vectorizer_bin.fit_transform(text[type]).todense()))\n",
    "        freq[type] = [v_freq, ratings[type]]\n",
    "        bin[type] = [v_bin, ratings[type]]\n",
    "\n",
    "    # return bin, freq\n",
    "    return bin, freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_bin, yelp_freq = convert_bow(yelp_text, yelp_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns F1-measure for benchmark classifiers, i.e. majority and random classifiers\n",
    "\n",
    "def ref_clf(clf_list, dataset):\n",
    "    for clf in clf_list:\n",
    "        clf[0].fit(dataset['train'][0], dataset['train'][1])\n",
    "        pred = clf[0].predict(dataset['test'][0])\n",
    "        print(clf[1] + ' F1-measure: ' + str(f1_score(yelp_test_rate, pred, average='micro')))\n",
    "        print('\\n')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that trains, evaluate classifier and returns best parameters, and F1-measure on train, valid and test sets\n",
    "\n",
    "def train_clf(dataset, classifier, parameters):\n",
    "    if parameters != None:\n",
    "        classifier = tune_hyper_params(classifier, dataset, params)\n",
    "\n",
    "        train_val_feat = sparse.vstack([dataset['train'][0], dataset['valid'][0]])\n",
    "        train_val_ratings = np.concatenate((dataset['train'][1], dataset['valid'][1]))\n",
    "\n",
    "        classifier.fit(train_val_feat, train_val_ratings)\n",
    "\n",
    "    else:\n",
    "        classifier.fit(dataset['train'][0], dataset['train'][1])\n",
    "\n",
    "    pred_train = f1_score(dataset['train'][1], classifier.predict(dataset['train'][0]), average='micro')\n",
    "    pred_val = f1_score(dataset['valid'][1], classifier.predict(dataset['valid'][0]), average='micro')\n",
    "    pred_test = f1_score(dataset['test'][1], classifier.predict(dataset['test'][0]), average='micro')\n",
    "\n",
    "    f1 = {'F1-measure Train': pred_train, 'F1-measure Valid': pred_val, 'F1-measure Test': pred_test}\n",
    "    best_param = None if parameters == None else classifier.best_params_\n",
    "\n",
    "    return f1, best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM\n",
      "{'F1-measure Train': 0.99642857142857144, 'F1-measure Valid': 0.45900000000000002, 'F1-measure Test': 0.44500000000000001}\n",
      "Best params - None\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM\n",
    "params = [{'max_iter': [100 * i for i in range(10)]}]\n",
    "f1_SVM, best_params = train_clf(yelp_bin, LinearSVC(), None)\n",
    "print('Linear SVM')\n",
    "print(f1_SVM)\n",
    "print('Best params - ' + str(best_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "{'F1-measure Train': 0.99142857142857144, 'F1-measure Valid': 0.374, 'F1-measure Test': 0.39149999999999996}\n",
      "Best params - None\n"
     ]
    }
   ],
   "source": [
    "f1_rand_forest, best_params = train_clf(yelp_bin, RandomForestClassifier(), None)\n",
    "print('Random Forest')\n",
    "print(f1_rand_forest)\n",
    "print('Best params - ' + str(best_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Gradient Boosted Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "{'F1-measure Train': 0.66085714285714281, 'F1-measure Valid': 0.45200000000000001, 'F1-measure Test': 0.47599999999999998}\n",
      "Best params - None\n"
     ]
    }
   ],
   "source": [
    "f1_grad_boosted, best_params = train_clf(yelp_bin, GradientBoostingClassifier(), None)\n",
    "print('Random Forest')\n",
    "print(f1_grad_boosted)\n",
    "print('Best params - ' + str(best_params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
