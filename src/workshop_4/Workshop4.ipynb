{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 4 - Fundamental ML Algorithms Part II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll explore the **support vector machine**, and ensemble methods such as **random forests** and **gradient boosted trees**. To do so, we'll be working with the Yelp dataset, consisting of variable length text reviews, and corresponding star ratings from 1 to 5. The problem at hand is to perform basic sentiment analysis (phrased as a classification task),  by predicting what star rating a new Yelp review would generate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preprocessing / Preparing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify paths to read and write data from\n",
    "dataPath = './dataset/'\n",
    "\n",
    "# Basic regex feature to help preprocess text\n",
    "regex = re.compile('[^\\w\\s]')\n",
    "\n",
    "FEATURES = 10000 # we will be inspecting 10 000 most common words in the training set\n",
    "data_types = ['train', 'valid', 'test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some helper methods to help us perform preprocessing tasks on the Yelp dataset. Recall that machine learning models can only directly interpret numbers, so we must encode the reviews and ratings. We attempt the following strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Preprocessing function: lowercase, remove punctuation. Returns list of lists (of clean lines), ratings''' \n",
    "def preprocess(filePath):\n",
    "    with open(filePath, 'r', encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "        reviews, ratings = [], []\n",
    "        for l in lines:\n",
    "            splitted = l.split('\\t')\n",
    "            ratings.append(int(splitted[1].strip()))\n",
    "            reviews.append(regex.sub('', splitted[0].strip()).lower())\n",
    "\n",
    "    return reviews, ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have 3 different files for train, validation and test sets, respectively\n",
    "# Inspect .txt files\n",
    "# Preprocess these .txt files and separate into features, labels for supervised classification problem\n",
    "X_train, y_train = preprocess(dataPath + 'yelp-train.txt')\n",
    "X_val, y_val = preprocess(dataPath + 'yelp-valid.txt')\n",
    "X_test, y_test = preprocess(dataPath + 'yelp-test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'best nights to go to postinos are mondays and tuesdays  they offer 20 deals where you get 4 slices of bruschetta out of the 12 that they offer and one whole bottle of the house wine  each bruschetta slice is probably the size of maybe your hand with your fingers outstretched  if youre a petite girl     they then cut each slice into 4s  perfect for sharingwe went on a monday night after 8pm and ordered 2 bottles of wine the 2 orders of the bruschetta which were 8 slices for those that cant count and a bowl of olives  the total came out to about 50thats a little over 13person wo tip  awesome    plus they have complementary valet parking everything was just fantastic ive never had fig before and they made my experience there quite memorable  i definitely recommend you come in regardless if its for their 20 deals on montues or not  theyve got great food and i will be back'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect sample of the training data review\n",
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect corresponding rating, do this for a few samples\n",
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dictionaries\n",
    "yelp_text = {'train': X_train, 'valid': X_val, 'test': X_test}\n",
    "yelp_ratings = {'train': y_train, 'valid': y_val, 'test': y_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Function returns takes in list of lists (of lines), returns list of n most freq. words '''\n",
    "def top_n_words(linesOfLines, n):\n",
    "    count = Counter([word for line in linesOfLines for word in line.split()]).most_common(n)\n",
    "    top_features = [word[0] for word in count]\n",
    "\n",
    "    return top_features, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return top 10 000 features for dataset\n",
    "yelp_vocab, yelp_count = top_n_words(X_train, FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'and',\n",
       " 'a',\n",
       " 'i',\n",
       " 'to',\n",
       " 'of',\n",
       " 'was',\n",
       " 'is',\n",
       " 'it',\n",
       " 'for',\n",
       " 'in',\n",
       " 'that',\n",
       " 'my',\n",
       " 'with',\n",
       " 'but',\n",
       " 'you',\n",
       " 'this',\n",
       " 'they',\n",
       " 'on',\n",
       " 'have',\n",
       " 'we',\n",
       " 'not',\n",
       " 'had',\n",
       " 'are',\n",
       " 'place',\n",
       " 'good',\n",
       " 'at',\n",
       " 'so',\n",
       " 'were',\n",
       " 'food',\n",
       " 'be',\n",
       " 'as',\n",
       " 'there',\n",
       " 'great',\n",
       " 'like',\n",
       " 'if',\n",
       " 'its',\n",
       " 'me',\n",
       " 'all',\n",
       " 'just',\n",
       " 'very',\n",
       " 'out',\n",
       " 'here',\n",
       " 'one',\n",
       " 'or',\n",
       " 'get',\n",
       " 'their',\n",
       " 'from',\n",
       " 'up',\n",
       " 'go',\n",
       " 'really',\n",
       " 'when',\n",
       " 'our',\n",
       " 'time',\n",
       " 'about',\n",
       " 'some',\n",
       " 'would',\n",
       " 'service',\n",
       " 'an',\n",
       " 'your',\n",
       " 'what',\n",
       " 'can',\n",
       " 'been',\n",
       " 'which',\n",
       " 'back',\n",
       " 'more',\n",
       " 'dont',\n",
       " 'only',\n",
       " 'also',\n",
       " 'will',\n",
       " 'by',\n",
       " 'no',\n",
       " 'love',\n",
       " 'has',\n",
       " 'little',\n",
       " 'too',\n",
       " 'nice',\n",
       " 'im',\n",
       " 'other',\n",
       " 'because',\n",
       " 'well',\n",
       " 'always',\n",
       " 'ive',\n",
       " 'than',\n",
       " 'them',\n",
       " 'do',\n",
       " 'even',\n",
       " 'us',\n",
       " 'best',\n",
       " 'pretty',\n",
       " 'got',\n",
       " 'he',\n",
       " 'after',\n",
       " 'she',\n",
       " 'much',\n",
       " 'chicken',\n",
       " 'try',\n",
       " 'ordered',\n",
       " 'restaurant',\n",
       " 'menu',\n",
       " 'people',\n",
       " 'know',\n",
       " 'think',\n",
       " 'could',\n",
       " 'didnt',\n",
       " 'first',\n",
       " 'am',\n",
       " 'order',\n",
       " 'make',\n",
       " 'went',\n",
       " 'over',\n",
       " 'never',\n",
       " 'staff',\n",
       " 'friendly',\n",
       " 'bar',\n",
       " 'did',\n",
       " 'better',\n",
       " 'then',\n",
       " 'way',\n",
       " 'night',\n",
       " 'who',\n",
       " 'going',\n",
       " 'off',\n",
       " 'how',\n",
       " 'right',\n",
       " 'few',\n",
       " 'cheese',\n",
       " 'came',\n",
       " 'say',\n",
       " 'two',\n",
       " 'pizza',\n",
       " 'made',\n",
       " 'want',\n",
       " 'delicious',\n",
       " 'come',\n",
       " 'salad',\n",
       " 'any',\n",
       " 'new',\n",
       " 'now',\n",
       " 'lunch',\n",
       " 'still',\n",
       " 'again',\n",
       " 'sauce',\n",
       " 'take',\n",
       " 'fresh',\n",
       " 'before',\n",
       " 'see',\n",
       " 'while',\n",
       " 'sure',\n",
       " 'since',\n",
       " 'cant',\n",
       " 'eat',\n",
       " 'experience',\n",
       " 'definitely',\n",
       " 'find',\n",
       " 'around',\n",
       " 'day',\n",
       " 'her',\n",
       " 'something',\n",
       " 'down',\n",
       " 'wait',\n",
       " 'happy',\n",
       " 'most',\n",
       " 'every',\n",
       " 'many',\n",
       " 'ever',\n",
       " 'bit',\n",
       " 'times',\n",
       " 'everything',\n",
       " 'amazing',\n",
       " '2',\n",
       " 'give',\n",
       " 'though',\n",
       " 'said',\n",
       " 'table',\n",
       " 'into',\n",
       " 'next',\n",
       " 'area',\n",
       " 'dinner',\n",
       " 'bad',\n",
       " 'lot',\n",
       " 'location',\n",
       " 'thing',\n",
       " 'being',\n",
       " 'meal',\n",
       " 'where',\n",
       " 'both',\n",
       " 'last',\n",
       " 'small',\n",
       " 'hour',\n",
       " 'side',\n",
       " 'phoenix',\n",
       " 'prices',\n",
       " 'another',\n",
       " 'favorite',\n",
       " 'youre',\n",
       " '3',\n",
       " '5',\n",
       " 'wasnt',\n",
       " 'big',\n",
       " 'hot',\n",
       " 'sandwich',\n",
       " 'drink',\n",
       " 'things',\n",
       " 'home',\n",
       " 'beer',\n",
       " 'store',\n",
       " 'his',\n",
       " 'thats',\n",
       " 'sweet',\n",
       " 'tasty',\n",
       " 'feel',\n",
       " 'drinks',\n",
       " 'burger',\n",
       " 'minutes',\n",
       " 'wine',\n",
       " 'stars',\n",
       " 'worth',\n",
       " 'should',\n",
       " 'enough',\n",
       " 'looking',\n",
       " 'took',\n",
       " 'long',\n",
       " 'friends',\n",
       " 'work',\n",
       " 'fries',\n",
       " 'different',\n",
       " 'bread',\n",
       " 'need',\n",
       " 'awesome',\n",
       " 'atmosphere',\n",
       " 'tried',\n",
       " 'taste',\n",
       " 'recommend',\n",
       " 'room',\n",
       " 'huge',\n",
       " 'years',\n",
       " 'old',\n",
       " 'excellent',\n",
       " 'price',\n",
       " 'clean',\n",
       " 'actually',\n",
       " 'asked',\n",
       " 'breakfast',\n",
       " 'these',\n",
       " 'selection',\n",
       " 'those',\n",
       " '4',\n",
       " 'coffee',\n",
       " 'places',\n",
       " 'id',\n",
       " 'found',\n",
       " 'once',\n",
       " 'visit',\n",
       " 'meat',\n",
       " 'quite',\n",
       " 'probably',\n",
       " 'special',\n",
       " 'friend',\n",
       " 'wanted',\n",
       " 'nothing',\n",
       " 'ok',\n",
       " 'each',\n",
       " 'thought',\n",
       " 'anything',\n",
       " 'same',\n",
       " 'kind',\n",
       " 'super',\n",
       " 'quality',\n",
       " 'server',\n",
       " 'scottsdale',\n",
       " 'usually',\n",
       " 'look',\n",
       " 'flavor',\n",
       " 'rice',\n",
       " 'free',\n",
       " 'perfect',\n",
       " 'full',\n",
       " 'why',\n",
       " 'large',\n",
       " 'sushi',\n",
       " 'check',\n",
       " 'cream',\n",
       " 'maybe',\n",
       " 'house',\n",
       " 'dish',\n",
       " 'cool',\n",
       " 'top',\n",
       " 'beef',\n",
       " 'ill',\n",
       " 'told',\n",
       " 'outside',\n",
       " 'used',\n",
       " 'without',\n",
       " 'away',\n",
       " 'far',\n",
       " 'town',\n",
       " 'however',\n",
       " 'items',\n",
       " 'review',\n",
       " 'fun',\n",
       " 'fried',\n",
       " 'decided',\n",
       " 'served',\n",
       " 'having',\n",
       " 'loved',\n",
       " 'getting',\n",
       " 'enjoy',\n",
       " 'ask',\n",
       " 'left',\n",
       " 'least',\n",
       " '10',\n",
       " 'inside',\n",
       " 'spot',\n",
       " 'open',\n",
       " 'three',\n",
       " 'parking',\n",
       " 'pork',\n",
       " 'else',\n",
       " 'may',\n",
       " 'everyone',\n",
       " 'patio',\n",
       " 'decent',\n",
       " 'enjoyed',\n",
       " 'half',\n",
       " 'through',\n",
       " 'family',\n",
       " 'put',\n",
       " 'spicy',\n",
       " 'red',\n",
       " 'soup',\n",
       " 'couple',\n",
       " 'makes',\n",
       " 'dishes',\n",
       " 'hard',\n",
       " 'busy',\n",
       " 'restaurants',\n",
       " 'whole',\n",
       " 'music',\n",
       " 'high',\n",
       " 'ice',\n",
       " 'water',\n",
       " 'almost',\n",
       " 'plate',\n",
       " 'close',\n",
       " 'eating',\n",
       " 'course',\n",
       " 'oh',\n",
       " 'wont',\n",
       " 'isnt',\n",
       " 'chips',\n",
       " 'such',\n",
       " 'kids',\n",
       " 'fantastic',\n",
       " 'live',\n",
       " 'part',\n",
       " 'mexican',\n",
       " 'wonderful',\n",
       " 'does',\n",
       " 'husband',\n",
       " 'fan',\n",
       " 'doesnt',\n",
       " 'green',\n",
       " 'dining',\n",
       " 'several',\n",
       " 'care',\n",
       " 'chocolate',\n",
       " 'during',\n",
       " 'let',\n",
       " 'local',\n",
       " 'tables',\n",
       " 'tasted',\n",
       " 'star',\n",
       " 'reviews',\n",
       " 'own',\n",
       " 'looked',\n",
       " 'hours',\n",
       " 'liked',\n",
       " 'fast',\n",
       " 'shop',\n",
       " 'tacos',\n",
       " 'especially',\n",
       " 'fish',\n",
       " 'waitress',\n",
       " 'shrimp',\n",
       " 'him',\n",
       " 'stuff',\n",
       " 'steak',\n",
       " 'customer',\n",
       " 'use',\n",
       " 'someone',\n",
       " 'might',\n",
       " 'coming',\n",
       " 'must',\n",
       " 'guy',\n",
       " 'valley',\n",
       " 'week',\n",
       " 'less',\n",
       " 'either',\n",
       " 'business',\n",
       " 'yes',\n",
       " 'door',\n",
       " 'yet',\n",
       " 'done',\n",
       " '1',\n",
       " 'quick',\n",
       " 'sit',\n",
       " 'finally',\n",
       " 'real',\n",
       " 'name',\n",
       " 'stop',\n",
       " 'although',\n",
       " 'bring',\n",
       " 'tell',\n",
       " 'started',\n",
       " 'overall',\n",
       " 'myself',\n",
       " 'trying',\n",
       " 'end',\n",
       " 'fact',\n",
       " 'thai',\n",
       " 'line',\n",
       " 'salsa',\n",
       " 'front',\n",
       " 'cheap',\n",
       " 'seems',\n",
       " 'style',\n",
       " 'keep',\n",
       " 'gave',\n",
       " 'comes',\n",
       " 'waiting',\n",
       " 'seemed',\n",
       " 'often',\n",
       " 'disappointed',\n",
       " 'street',\n",
       " 'call',\n",
       " 'drive',\n",
       " 'cooked',\n",
       " 'decor',\n",
       " 'until',\n",
       " 'yummy',\n",
       " 'couldnt',\n",
       " 'felt',\n",
       " 'money',\n",
       " 'year',\n",
       " 'dessert',\n",
       " 'walked',\n",
       " 'theyre',\n",
       " 'pay',\n",
       " 'lots',\n",
       " 'tea',\n",
       " 'called',\n",
       " 'walk',\n",
       " 'extra',\n",
       " 'able',\n",
       " 'bacon',\n",
       " 'theres',\n",
       " '20',\n",
       " 'brought',\n",
       " 'deal',\n",
       " 'kitchen',\n",
       " 'today',\n",
       " 'waiter',\n",
       " 'instead',\n",
       " 'sat',\n",
       " 'helpful',\n",
       " 'group',\n",
       " 'glass',\n",
       " 'bbq',\n",
       " 'guess',\n",
       " 'wish',\n",
       " 'regular',\n",
       " 'offer',\n",
       " 'wife',\n",
       " 'white',\n",
       " 'absolutely',\n",
       " 'wrong',\n",
       " 'wouldnt',\n",
       " 'second',\n",
       " 'saw',\n",
       " 'needed',\n",
       " 'options',\n",
       " 'seem',\n",
       " 'light',\n",
       " 'plus',\n",
       " 'reason',\n",
       " 'person',\n",
       " 'beans',\n",
       " 'highly',\n",
       " 'yelp',\n",
       " 'okay',\n",
       " 'buy',\n",
       " 'fine',\n",
       " 'expect',\n",
       " 'help',\n",
       " 'start',\n",
       " 'return',\n",
       " 'morning',\n",
       " 'flavors',\n",
       " 'owner',\n",
       " 'gets',\n",
       " 'point',\n",
       " 'serve',\n",
       " 'stay',\n",
       " 'saturday',\n",
       " 'mind',\n",
       " 'ago',\n",
       " 'dog',\n",
       " 'job',\n",
       " 'size',\n",
       " 'potato',\n",
       " 'seating',\n",
       " 'seen',\n",
       " 'ate',\n",
       " 'warm',\n",
       " 'hotel',\n",
       " 'impressed',\n",
       " 'appetizer',\n",
       " 'looks',\n",
       " 'choice',\n",
       " 'pool',\n",
       " 'arrived',\n",
       " 'arizona',\n",
       " 'making',\n",
       " 'easy',\n",
       " 'roll',\n",
       " 'youll',\n",
       " 'four',\n",
       " 'bowl',\n",
       " 'later',\n",
       " 'party',\n",
       " 'between',\n",
       " 'list',\n",
       " 'wings',\n",
       " 'pick',\n",
       " 'havent',\n",
       " 'grilled',\n",
       " 'car',\n",
       " 'beautiful',\n",
       " 'rolls',\n",
       " 'etc',\n",
       " 'perfectly',\n",
       " 'burrito',\n",
       " 'potatoes',\n",
       " 'tempe',\n",
       " 'portions',\n",
       " 'chinese',\n",
       " 'add',\n",
       " 'type',\n",
       " 'sandwiches',\n",
       " 'early',\n",
       " 'past',\n",
       " 'ingredients',\n",
       " 'days',\n",
       " 'cute',\n",
       " 'game',\n",
       " 'ended',\n",
       " 'mall',\n",
       " 'choose',\n",
       " 'late',\n",
       " 'anyone',\n",
       " 'extremely',\n",
       " 'cold',\n",
       " 'remember',\n",
       " 'quickly',\n",
       " '6',\n",
       " 'leave',\n",
       " 'dry',\n",
       " 'trip',\n",
       " 'guys',\n",
       " 'seated',\n",
       " 'sitting',\n",
       " 'packed',\n",
       " 'customers',\n",
       " 'variety',\n",
       " 'attentive',\n",
       " 'burgers',\n",
       " 'amount',\n",
       " 'plenty',\n",
       " 'friday',\n",
       " '15',\n",
       " 'twice',\n",
       " 'priced',\n",
       " 'french',\n",
       " 'across',\n",
       " 'hit',\n",
       " 'cake',\n",
       " 'reasonable',\n",
       " 'date',\n",
       " 'counter',\n",
       " 'run',\n",
       " 'seriously',\n",
       " 'butter',\n",
       " 'average',\n",
       " 'cut',\n",
       " 'problem',\n",
       " 'believe',\n",
       " 'manager',\n",
       " 'along',\n",
       " 'park',\n",
       " 'sometimes',\n",
       " '12',\n",
       " 'heard',\n",
       " 'waited',\n",
       " 'egg',\n",
       " 'under',\n",
       " 'rather',\n",
       " 'working',\n",
       " 'sunday',\n",
       " 'show',\n",
       " 'shopping',\n",
       " 'near',\n",
       " 'unique',\n",
       " 'weekend',\n",
       " 'soon',\n",
       " 'eaten',\n",
       " 'watch',\n",
       " 'employees',\n",
       " 'az',\n",
       " 'mean',\n",
       " 'short',\n",
       " 'comfortable',\n",
       " 'others',\n",
       " 'five',\n",
       " 'bite',\n",
       " 'main',\n",
       " 'downtown',\n",
       " 'crust',\n",
       " 'slow',\n",
       " 'bill',\n",
       " 'garlic',\n",
       " 'surprised',\n",
       " 'eggs',\n",
       " 'beers',\n",
       " 'set',\n",
       " 'neighborhood',\n",
       " 'ones',\n",
       " 'already',\n",
       " 'tip',\n",
       " 'corn',\n",
       " 'pasta',\n",
       " 'behind',\n",
       " 'crowd',\n",
       " 'ready',\n",
       " 'onion',\n",
       " 'italian',\n",
       " 'knew',\n",
       " 'simple',\n",
       " 'glad',\n",
       " 'stopped',\n",
       " 'evening',\n",
       " 'man',\n",
       " 'doing',\n",
       " 'taking',\n",
       " 'totally',\n",
       " 'given',\n",
       " 'girl',\n",
       " 'space',\n",
       " 'entire',\n",
       " 'authentic',\n",
       " 'tomato',\n",
       " 'walking',\n",
       " 'salads',\n",
       " 'ambiance',\n",
       " 'loud',\n",
       " 'head',\n",
       " 'expensive',\n",
       " 'available',\n",
       " 'servers',\n",
       " 'life',\n",
       " 'offered',\n",
       " 'chef',\n",
       " 'read',\n",
       " 'mom',\n",
       " 'school',\n",
       " 'crispy',\n",
       " 'specials',\n",
       " 'market',\n",
       " 'hope',\n",
       " 'taco',\n",
       " 'yourself',\n",
       " 'ordering',\n",
       " 'itself',\n",
       " 'flavorful',\n",
       " 'arent',\n",
       " '30',\n",
       " 'portion',\n",
       " 'expected',\n",
       " 'feeling',\n",
       " 'sausage',\n",
       " 'moved',\n",
       " 'hand',\n",
       " 'cost',\n",
       " 'please',\n",
       " 'completely',\n",
       " 'kept',\n",
       " 'black',\n",
       " 'sort',\n",
       " 'wow',\n",
       " 'gone',\n",
       " 'card',\n",
       " 'spend',\n",
       " 'plates',\n",
       " 'hair',\n",
       " 'months',\n",
       " 'appetizers',\n",
       " 'cup',\n",
       " 'choices',\n",
       " 'hands',\n",
       " 'rest',\n",
       " 'idea',\n",
       " 'werent',\n",
       " 'world',\n",
       " 'located',\n",
       " 'dark',\n",
       " 'foods',\n",
       " 'entrees',\n",
       " 'opened',\n",
       " 'chain',\n",
       " '8',\n",
       " 'thanks',\n",
       " 'grab',\n",
       " 'center',\n",
       " 'pho',\n",
       " 'toppings',\n",
       " 'recently',\n",
       " 'typical',\n",
       " 'interesting',\n",
       " 'miss',\n",
       " 'including',\n",
       " 'birthday',\n",
       " 'unfortunately',\n",
       " 'change',\n",
       " 'bottle',\n",
       " 'tastes',\n",
       " 'hungry',\n",
       " 'onions',\n",
       " 'cafe',\n",
       " 'curry',\n",
       " 'exactly',\n",
       " 'meals',\n",
       " 'bucks',\n",
       " 'play',\n",
       " 'needs',\n",
       " 'pieces',\n",
       " 'bland',\n",
       " 'toast',\n",
       " 'asian',\n",
       " 'excited',\n",
       " 'joint',\n",
       " 'empty',\n",
       " 'saying',\n",
       " 'together',\n",
       " 'kinda',\n",
       " 'crowded',\n",
       " 'lettuce',\n",
       " 'thank',\n",
       " 'club',\n",
       " 'homemade',\n",
       " 'summer',\n",
       " 'mac',\n",
       " 'grill',\n",
       " 'office',\n",
       " 'charge',\n",
       " 'pricey',\n",
       " 'truly',\n",
       " 'tiny',\n",
       " 'spring',\n",
       " 'bartender',\n",
       " 'unless',\n",
       " 'outdoor',\n",
       " 'wall',\n",
       " 'veggies',\n",
       " 'understand',\n",
       " 'recommended',\n",
       " 'blue',\n",
       " 'noticed',\n",
       " 'afternoon',\n",
       " 'chance',\n",
       " 'mixed',\n",
       " 'longer',\n",
       " 'stand',\n",
       " 'giving',\n",
       " 'anyway',\n",
       " 'w',\n",
       " 'talk',\n",
       " 'owners',\n",
       " 'salmon',\n",
       " 'event',\n",
       " 'noodles',\n",
       " '7',\n",
       " 'yeah',\n",
       " 'cannot',\n",
       " 'hate',\n",
       " 'crab',\n",
       " 'pleasant',\n",
       " 'tender',\n",
       " 'strip',\n",
       " 'dressing',\n",
       " 'stores',\n",
       " 'company',\n",
       " 'within',\n",
       " 'frozen',\n",
       " 'casual',\n",
       " 'number',\n",
       " 'note',\n",
       " 'shared',\n",
       " 'forward',\n",
       " 'true',\n",
       " 'dip',\n",
       " 'closed',\n",
       " 'la',\n",
       " 'yum',\n",
       " 'movie',\n",
       " 'oil',\n",
       " 'veggie',\n",
       " 'greasy',\n",
       " 'sides',\n",
       " 'mouth',\n",
       " 'phone',\n",
       " 'single',\n",
       " 'anywhere',\n",
       " 'soft',\n",
       " 'spinach',\n",
       " 'fabulous',\n",
       " 'desert',\n",
       " 'piece',\n",
       " 'case',\n",
       " 'goes',\n",
       " 'pie',\n",
       " 'above',\n",
       " 'prepared',\n",
       " '100',\n",
       " 'watching',\n",
       " 'weeks',\n",
       " 'low',\n",
       " 'dirty',\n",
       " 'craving',\n",
       " 'filled',\n",
       " 'lovely',\n",
       " 'girls',\n",
       " 'entree',\n",
       " 'lets',\n",
       " 'slightly',\n",
       " 'ribs',\n",
       " 'bought',\n",
       " 'orders',\n",
       " 'share',\n",
       " 'sports',\n",
       " 'sorry',\n",
       " 'takes',\n",
       " 'dogs',\n",
       " 'upon',\n",
       " 'pita',\n",
       " 'youve',\n",
       " 'thin',\n",
       " 'lady',\n",
       " 'serving',\n",
       " 'talking',\n",
       " 'literally',\n",
       " 'finish',\n",
       " 'mix',\n",
       " 'based',\n",
       " 'playing',\n",
       " 'healthy',\n",
       " 'fruit',\n",
       " 'tuna',\n",
       " 'spent',\n",
       " 'value',\n",
       " 'worst',\n",
       " 'total',\n",
       " 'horrible',\n",
       " 'face',\n",
       " 'tomatoes',\n",
       " 'except',\n",
       " 'dr',\n",
       " 'fairly',\n",
       " 'tasting',\n",
       " 'added',\n",
       " 'bag',\n",
       " 'box',\n",
       " 'city',\n",
       " 'thinking',\n",
       " 'somewhere',\n",
       " 'whatever',\n",
       " 'easily',\n",
       " 'pizzas',\n",
       " 'corner',\n",
       " 'floor',\n",
       " 'tons',\n",
       " 'fair',\n",
       " 'airport',\n",
       " 'says',\n",
       " 'simply',\n",
       " 'weve',\n",
       " 'stuffed',\n",
       " 'due',\n",
       " 'vegetarian',\n",
       " 'item',\n",
       " 'hang',\n",
       " 'split',\n",
       " 'finished',\n",
       " 'prefer',\n",
       " 'view',\n",
       " 'terrible',\n",
       " 'perhaps',\n",
       " 'roasted',\n",
       " 'mine',\n",
       " 'buffet',\n",
       " 'pulled',\n",
       " 'cash',\n",
       " 'works',\n",
       " 'received',\n",
       " 'forget',\n",
       " 'immediately',\n",
       " 'seats',\n",
       " 'hear',\n",
       " 'boyfriend',\n",
       " 'beat',\n",
       " 'sign',\n",
       " 'book',\n",
       " 'month',\n",
       " 'taken',\n",
       " 'sauces',\n",
       " 'filling',\n",
       " 'brunch',\n",
       " 'alone',\n",
       " 'chili',\n",
       " 'vibe',\n",
       " 'picked',\n",
       " 'building',\n",
       " 'stayed',\n",
       " 'attention',\n",
       " 'paying',\n",
       " 'games',\n",
       " 'art',\n",
       " 'middle',\n",
       " 'crazy',\n",
       " 'orange',\n",
       " 'section',\n",
       " 'mostly',\n",
       " 'word',\n",
       " 'lived',\n",
       " '9',\n",
       " 'paid',\n",
       " 'heat',\n",
       " 'means',\n",
       " 'turkey',\n",
       " 'weird',\n",
       " 'seat',\n",
       " 'baked',\n",
       " 'personal',\n",
       " 'certainly',\n",
       " 'salty',\n",
       " 'mention',\n",
       " 'traditional',\n",
       " 'daughter',\n",
       " 'hummus',\n",
       " 'north',\n",
       " 'shot',\n",
       " 'treat',\n",
       " 'damn',\n",
       " 'east',\n",
       " 'visiting',\n",
       " 'soda',\n",
       " 'slice',\n",
       " 'tortilla',\n",
       " 'iced',\n",
       " 'seafood',\n",
       " 'honestly',\n",
       " 'greeted',\n",
       " 'yogurt',\n",
       " 'carne',\n",
       " 'nearly',\n",
       " 'suggest',\n",
       " 'sad',\n",
       " 'mood',\n",
       " 'option',\n",
       " 'matter',\n",
       " 'reasonably',\n",
       " '50',\n",
       " 'sound',\n",
       " 'minute',\n",
       " 'combo',\n",
       " 'baby',\n",
       " 'bars',\n",
       " 'lack',\n",
       " 'crisp',\n",
       " 'reading',\n",
       " 'seeing',\n",
       " 'nights',\n",
       " 'opinion',\n",
       " 'lamb',\n",
       " 'central',\n",
       " 'cook',\n",
       " 'asking',\n",
       " 'slices',\n",
       " 'visited',\n",
       " 'smell',\n",
       " 'worked',\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect some of the most common words\n",
    "yelp_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Function that converts preprocessed text to binary, frequency bag-of-words representations with corresponding ratings '''\n",
    "def convert_bow(text, ratings):\n",
    "    binary = {}\n",
    "    freq = {}\n",
    "\n",
    "    vectorizer = CountVectorizer(vocabulary=yelp_vocab)\n",
    "    vectorizer_bin = CountVectorizer(vocabulary=yelp_vocab, binary=True)\n",
    "    # data_types referenced globally, bad practice\n",
    "    for dtype in data_types:\n",
    "        v_freq = np.array(normalize(vectorizer.fit_transform(text[dtype]).todense()))\n",
    "        v_bin = sparse.csr_matrix(np.array(vectorizer_bin.fit_transform(text[dtype]).todense()))\n",
    "        # Appends transformed bag-of-words representation, and corresponding ratings\n",
    "        freq[dtype] = [v_freq, ratings[dtype]]\n",
    "        binary[dtype] = [v_bin, ratings[dtype]]\n",
    "\n",
    "    # return bin, freq\n",
    "    return binary, freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to binary and frequency bag-of-words representation\n",
    "yelp_bin, yelp_freq = convert_bow(yelp_text, yelp_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 10000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect values of binary bag-of-words representation\n",
    "# Inspect sparse matrix shapes\n",
    "yelp_bin['train'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect corresponding ratings\n",
    "print(len(yelp_bin['train'][1]))\n",
    "yelp_bin['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.50702013,  0.20280805,  0.        , ...,  0.        ,\n",
       "        0.        ,  0.        ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect frequency bag-of-words sample values\n",
    "yelp_freq['train'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i cant believe i havent yelped about the place yet several months maybe over a year ago my husband read a newspaper article about the clover coffee maker and the one place in town that had managed to procure one i was skeptical as is my nature it cant be that much better right youre just saying its amazing because you want to talk about the new hot coffee shop you discovered right well maybe but i love this place and i dont think it has a whole lot to do with the clover they roast their own beans and they roast them way differently than that other ginormous coffee chain  all a light or medium roast never bitter never oily never yucky the coffee they make there is obviously the best but i send my husband in every week now to buy a pound of beans so that i can approximate the same coffee at home add an edgy though sometimes intimidating seating area great local art which we bought off the wall and smiley serviceim sold cant wait to try out the downtown location'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare with original text from same sample\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our bag-of-words-representations, we attempt to classify the data using algorithms seen today, e.g. SVMs, Random Forests, and Gradient-Boosted Trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define function to train and evaluate classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Function  to train, evaluate classifier and returns best parameters, accuracies on different sets '''\n",
    "def train_clf(dataset, clf, params):\n",
    "    \n",
    "    # Hyperparameter tuning\n",
    "    if params != None:\n",
    "        clf = tune_hyper_params(clf, dataset, params)\n",
    "        # Concatenate training, validation sets - use validation set to tune hyperparameters\n",
    "        X_train_val = sparse.vstack([dataset['train'][0], dataset['valid'][0]])\n",
    "        y_train_val = np.concatenate((dataset['train'][1], dataset['valid'][1]))\n",
    "\n",
    "        clf.fit(X_train_val, y_train_val)\n",
    "        \n",
    "    # If no hyperparameter tuning, fit on training data\n",
    "    else:\n",
    "        clf.fit(dataset['train'][0], dataset['train'][1])\n",
    "\n",
    "    acc_train = accuracy_score(dataset['train'][1], clf.predict(dataset['train'][0]))\n",
    "    acc_val = accuracy_score(dataset['valid'][1], clf.predict(dataset['valid'][0]))\n",
    "    acc_test = accuracy_score(dataset['test'][1], clf.predict(dataset['test'][0]))\n",
    "\n",
    "    acc = {'Train Accuracy': acc_train, 'Validation Accuracy': acc_val, 'Test Accuracy': acc_test}\n",
    "    best_param = None if params == None else clf.best_params_\n",
    "\n",
    "    return acc, best_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can evaluate different classifiers on both the binary and frequency bag-of-words representations of the Yelp dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVM\n",
    "params = [{'max_iter': [100 * i for i in range(10)]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM\n",
      "{'Train Accuracy': 0.996, 'Validation Accuracy': 0.996, 'Test Accuracy': 0.44750000000000001}\n",
      "Best params - {'max_iter': 200}\n"
     ]
    }
   ],
   "source": [
    "# Test on binary bag-of-words representation\n",
    "acc_SVM, best_params = train_clf(yelp_bin, LinearSVC(), params)\n",
    "print('Linear SVM')\n",
    "print(acc_SVM)\n",
    "print('Best params - {}'.format(best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM\n",
      "{'Train Accuracy': 0.80671428571428572, 'Validation Accuracy': 0.81000000000000005, 'Test Accuracy': 0.52000000000000002}\n",
      "Best params - {'max_iter': 100}\n"
     ]
    }
   ],
   "source": [
    "# Test on freq bag-of-words representation\n",
    "acc_SVM, best_params = train_clf(yelp_freq, LinearSVC(), params)\n",
    "print('Linear SVM')\n",
    "print(acc_SVM)\n",
    "print('Best params - {}'.format(best_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "{'Train Accuracy': 0.98928571428571432, 'Validation Accuracy': 0.36799999999999999, 'Test Accuracy': 0.39700000000000002}\n",
      "Best params - None\n"
     ]
    }
   ],
   "source": [
    "# Test on binary bag-of-words representation\n",
    "acc_rand_forest, best_params = train_clf(yelp_bin, RandomForestClassifier(), None)\n",
    "print('Random Forest')\n",
    "print(acc_rand_forest)\n",
    "print('Best params - {}'.format(best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "{'Train Accuracy': 0.99228571428571433, 'Validation Accuracy': 0.38300000000000001, 'Test Accuracy': 0.40000000000000002}\n",
      "Best params - None\n"
     ]
    }
   ],
   "source": [
    "acc_rand_forest, best_params = train_clf(yelp_freq, RandomForestClassifier(), None)\n",
    "print('Random Forest')\n",
    "print(acc_rand_forest)\n",
    "print('Best params - {}'.format(best_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosted Trees\n",
      "{'Train Accuracy': 0.75871428571428567, 'Validation Accuracy': 0.48899999999999999, 'Test Accuracy': 0.48599999999999999}\n",
      "Best params - None\n"
     ]
    }
   ],
   "source": [
    "acc_grad_boosted, best_params = train_clf(yelp_bin, GradientBoostingClassifier(subsample=0.75, n_estimators=200), None)\n",
    "print('Gradient Boosted Trees')\n",
    "print(acc_grad_boosted)\n",
    "print('Best params - {}'.format(best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_grad_boosted, best_params = train_clf(yelp_freq, GradientBoostingClassifier(), None)\n",
    "print('Gradient Boosted Trees')\n",
    "print(acc_grad_boosted)\n",
    "print('Best params - {}'.format(best_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS - Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy we obtained is not so great. What could we have done differently? First of all, we didn't get to tune hyperparameters(except for briefly on the SVM), so here's the method used for hyperparameter tuning on the validation set! Explore the sklearn documentation and try to beat the accuracy scores currently reached. Anything else? Inspect the most common words, what are they? Are they all useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns best hyper-parameters for given classifier, tunes parameters on validation set\n",
    "def tune_hyper_params(classifier, dataset, parameters):\n",
    "    ps = PredefinedSplit(test_fold=[-1 for i in range(dataset['train'][0].shape[0])] + [0 for i in range(dataset['valid'][0].shape[0])])\n",
    "    classifier = GridSearchCV(classifier, parameters, cv=ps, refit=True)\n",
    "\n",
    "    return classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
